{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c60a244",
   "metadata": {},
   "outputs": [],
   "source": [
    "language = 'pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb7f52f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\nconst sleep = time => new Promise(resolve => setTimeout(resolve, time));\n\nconst b2text = blob => new Promise(resolve => {\n    const reader = new FileReader();\n    reader.onloadend = e => resolve(e.target.result);\n    reader.readAsDataURL(blob);\n});\n\nvar record = time => new Promise(async resolve => {\n    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n    const recorder = new MediaRecorder(stream);\n    const chunks = [];\n\n    recorder.ondataavailable = e => chunks.push(e.data);\n    recorder.start();\n\n    await sleep(time);\n\n    recorder.onstop = async () => {\n        const blob = new Blob(chunks);\n        const text = await b2text(blob);\n        resolve(text);\n    };\n\n    recorder.stop();\n});\n",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'ZMQInteractiveShell' object has no attribute 'eval_js'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 59\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m file_name\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# =========================\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# EXECUÇÃO\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# =========================\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m record_file \u001b[38;5;241m=\u001b[39m record(\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m     60\u001b[0m display(Audio(record_file, autoplay\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n",
      "Cell \u001b[1;32mIn[7], line 47\u001b[0m, in \u001b[0;36mrecord\u001b[1;34m(sec)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecord\u001b[39m(sec\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m     46\u001b[0m     display(Javascript(RECORD))\n\u001b[1;32m---> 47\u001b[0m     js_result \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39meval_js(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecord(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msec\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1000\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     48\u001b[0m     audio \u001b[38;5;241m=\u001b[39m b64decode(js_result\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     50\u001b[0m     file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest_audio.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ZMQInteractiveShell' object has no attribute 'eval_js'"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# IMPORTS\n",
    "# =========================\n",
    "from IPython.display import Audio, display, Javascript\n",
    "from google.colab import output\n",
    "from base64 import b64decode\n",
    "\n",
    "# =========================\n",
    "# JAVASCRIPT PARA GRAVAÇÃO\n",
    "# =========================\n",
    "RECORD = \"\"\"\n",
    "const sleep = time => new Promise(resolve => setTimeout(resolve, time));\n",
    "\n",
    "const b2text = blob => new Promise(resolve => {\n",
    "    const reader = new FileReader();\n",
    "    reader.onloadend = e => resolve(e.target.result);\n",
    "    reader.readAsDataURL(blob);\n",
    "});\n",
    "\n",
    "var record = time => new Promise(async resolve => {\n",
    "    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n",
    "    const recorder = new MediaRecorder(stream);\n",
    "    const chunks = [];\n",
    "\n",
    "    recorder.ondataavailable = e => chunks.push(e.data);\n",
    "    recorder.start();\n",
    "\n",
    "    await sleep(time);\n",
    "\n",
    "    recorder.onstop = async () => {\n",
    "        const blob = new Blob(chunks);\n",
    "        const text = await b2text(blob);\n",
    "        resolve(text);\n",
    "    };\n",
    "\n",
    "    recorder.stop();\n",
    "});\n",
    "\"\"\"\n",
    "\n",
    "# =========================\n",
    "# FUNÇÃO PYTHON\n",
    "# =========================\n",
    "def record(sec=5):\n",
    "    display(Javascript(RECORD))\n",
    "    js_result = output.eval_js(f\"record({sec * 1000})\")\n",
    "    audio = b64decode(js_result.split(',')[1])\n",
    "\n",
    "    file_name = \"request_audio.wav\"\n",
    "    with open(file_name, \"wb\") as f:\n",
    "        f.write(audio)\n",
    "\n",
    "    return file_name\n",
    "\n",
    "# =========================\n",
    "# EXECUÇÃO\n",
    "# =========================\n",
    "print(\"OUVINDO....\\n\")\n",
    "record_file = record(5)\n",
    "display(Audio(record_file, autoplay=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adaf763",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install git+https://github.com/openai/whisper.git -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"small\")\n",
    "result = model.transcribe(record_file, fp16=False, language=language)\n",
    "transcription = result[\"text\"]\n",
    "print(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572bc06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openai==0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73faebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = '*******'\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[ {\"role\": \"user\", \"content\": transcription} ]\n",
    ")\n",
    "\n",
    "chatgpt_response = response.choices[0].message.content\n",
    "print(chatgpt_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a751947b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install gTTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3c675f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "\n",
    "gtts_object = gTTS(text=chatgpt_response, lang=language, slow=False)\n",
    "response_audio = \"/content/response_audio.wav\"\n",
    "gtts_object.save(response_audio)\n",
    "display(Audio(response_audio, autoplay=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
